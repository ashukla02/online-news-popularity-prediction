{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box plots of error rates over 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import pprint\n",
    "from timeit import timeit\n",
    "from functools import partial\n",
    "import seaborn as sbn\n",
    "np.random.seed(12345)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot as plt\n",
    "from random import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- constants(do not change) ---\n",
    "kFold = 10\n",
    "iters = 5\n",
    "cpus = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- data preparation utilities ---\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "# popularity detector\n",
    "def popular(s):\n",
    "    return 1 if s>1400 else 0\n",
    "\n",
    "#drop url and time, standardize everything else\n",
    "def prepare(data):\n",
    "    data_no_url_time = data.drop(['url',' timedelta'],axis = 1)\n",
    "    scaled_data = data_no_url_time.copy()\n",
    "    for column in data_no_url_time.columns:\n",
    "        if column!=' shares':\n",
    "            scaled_data[column] = preprocessing.scale(data_no_url_time[column])\n",
    "    scaled_data[' popularity'] = scaled_data[' shares'].apply(popular)\n",
    "    std_data = scaled_data.drop([' shares'],axis=1)\n",
    "    return std_data\n",
    "\n",
    "#takes dataframes containing both predictor and the output and separates them\n",
    "def make_train_test(train, test, lastColumnTrain, columnOutput):\n",
    "    x_train = train.loc[:,:lastColumnTrain]\n",
    "    y_train = train.loc[:,columnOutput]\n",
    "    x_test = test.loc[:,:lastColumnTrain]\n",
    "    y_test = test.loc[:,columnOutput]\n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O utilities\n",
    "def summary(cl, y_pred, y_test):\n",
    "    print (\"coefficients = \", cl.coef_)\n",
    "    print (\"intercepts = \", cl.intercept_)\n",
    "    print (\"iterations = \", cl.n_iter_)\n",
    "\n",
    "def plot_misclassification(m):\n",
    "    labels, data = [*zip(*m.items())]  # 'transpose' items to parallel key, value lists\n",
    "    plt.boxplot(data)\n",
    "    plt.xticks(range(1, len(labels) + 1), labels)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- classifiers ---\n",
    "alphas = np.logspace(-5,5,100)\n",
    "\n",
    "def logistic_plain_cv(x_train, y_train, x_test):\n",
    "    clf = LogisticRegressionCV(cv=kFold, \n",
    "                               max_iter=100000,\n",
    "                               n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred_test = [1 if p > 0.5 else 0 for p in clf.predict(x_test)]\n",
    "    y_pred_train = [1 if p > 0.5 else 0 for p in clf.predict(x_train)]\n",
    "    return clf, y_pred_train, y_pred_test\n",
    "\n",
    "def random_forest(x_train, y_train, x_test):\n",
    "    clf = RandomForestClassifier(n_estimators=100,\n",
    "                                n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred_test = [1 if p > 0.5 else 0 for p in clf.predict(x_test)]\n",
    "    y_pred_train = [1 if p > 0.5 else 0 for p in clf.predict(x_train)]\n",
    "    return clf, y_pred_train, y_pred_test\n",
    "\n",
    "def lasso_cv(x_train, y_train, x_test):\n",
    "    clf = LassoCV(alphas=alphas,\n",
    "                  cv=kFold,\n",
    "                  max_iter=100000)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred_test = [1 if p > 0.5 else 0 for p in clf.predict(x_test)]\n",
    "    y_pred_train = [1 if p > 0.5 else 0 for p in clf.predict(x_train)]\n",
    "    return clf, y_pred_train, y_pred_test\n",
    "\n",
    "def elastic_net_cv(x_train, y_train, x_test):\n",
    "    clf = ElasticNetCV(alphas=alphas,\n",
    "                       cv=kFold,\n",
    "                       max_iter=100000,\n",
    "                       n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred_test = [1 if p > 0.5 else 0 for p in clf.predict(x_test)]\n",
    "    y_pred_train = [1 if p > 0.5 else 0 for p in clf.predict(x_train)]\n",
    "    return clf, y_pred_train, y_pred_test\n",
    "\n",
    "def ridge_cv(x_train, y_train, x_test):\n",
    "    clf = RidgeCV(alphas=alphas,\n",
    "                  cv=kFold)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred_test = [1 if p > 0.5 else 0 for p in clf.predict(x_test)]\n",
    "    y_pred_train = [1 if p > 0.5 else 0 for p in clf.predict(x_train)]\n",
    "    return clf, y_pred_train, y_pred_test\n",
    "\n",
    "def svc(x_train, y_train, x_test):\n",
    "    parameter_space = [\n",
    "        {'kernel': ['rbf'],\n",
    "         'gamma': np.logspace(-1,2,10),\n",
    "         'C': np.logspace(-1,2,10)}\n",
    "    ]\n",
    "    clf = GridSearchCV(SVC(),\n",
    "                       parameter_space,\n",
    "                       cv=kFold,\n",
    "                       iid=True,\n",
    "                       scoring='accuracy',\n",
    "                       n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred_test = [1 if p > 0.5 else 0 for p in clf.predict(x_test)]\n",
    "    y_pred_train = [1 if p > 0.5 else 0 for p in clf.predict(x_train)]\n",
    "    return clf, y_pred_train, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- test models against fake data ---\n",
    "\n",
    "def make_data_up(noise):\n",
    "    data = {'predictor': [], 'output': []}\n",
    "    for i in range(1000):\n",
    "        r = random()\n",
    "        v = True if r > 0.5 else False\n",
    "        if random() < noise :\n",
    "            v = not v\n",
    "        data['predictor'].append(r)\n",
    "        data['output'].append(1 if v else 0)\n",
    "    made_up_data = pd.DataFrame(data)\n",
    "    made_up_data['predictor'] = preprocessing.scale(made_up_data['predictor'])\n",
    "    return made_up_data\n",
    "\n",
    "def test_with_fake_data(data, classifier):\n",
    "    p = data.loc[:,:'predictor'].columns.size\n",
    "    n = len(data.index)\n",
    "    learning_set_sizes = {'10p': 10*p, '50p': 50*p}\n",
    "    misclassification_rates = {'10p': [], '50p': []}\n",
    "    for iteration in range(iters):\n",
    "        for size_case in learning_set_sizes:\n",
    "            #print('-'*80)\n",
    "            #print (\"iteration: \", iteration+1, \" of \", iters)\n",
    "            #print(\"case: \", size_case)\n",
    "            size = learning_set_sizes[size_case]\n",
    "            #print(\"learning set size =\", size)\n",
    "            train_set,test_set = train_test_split(data, test_size= 1.0*size/n)\n",
    "            x_train, y_train, x_test, y_test = make_train_test(train_set, test_set, 'predictor', 'output')\n",
    "            clf, y_pred = classifier(x_train, y_train, x_test)\n",
    "            #summary(clf, y_pred, y_test)\n",
    "            misclassification_rates[size_case].append(1.0 - accuracy_score(y_test, y_pred))\n",
    "            #print('-'*80)\n",
    "    #print(\"Misclassification rates:\", misclassification_rates)\n",
    "    plot_misclassification(misclassification_rates)\n",
    "    \n",
    "fake_data = make_data_up(0.1)\n",
    "\n",
    "# print(\"---RANDOM FOREST---\")\n",
    "# test_with_fake_data(fake_data, random_forest)\n",
    "# print(\"---RADIAL SVM---\")\n",
    "# test_with_fake_data(fake_data, svc)\n",
    "# print(\"---LOGISTIC CV---\")\n",
    "# test_with_fake_data(fake_data, logistic_plain_cv)\n",
    "# print(\"---LOGISTIC LASSO CV---\")\n",
    "# test_with_fake_data(fake_data, lasso_cv)\n",
    "# print(\"---LOGISTIC ELASTIC NET CV---\")\n",
    "# test_with_fake_data(fake_data, elastic_net_cv)\n",
    "# print(\"---LOGISTIC RIDGE CV---\")\n",
    "# test_with_fake_data(fake_data, ridge_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- engine to run model ---\n",
    "results = {}\n",
    "def run_model(data, name, classifier):\n",
    "    lastPredictor = ' abs_title_sentiment_polarity'\n",
    "    columnOutput = ' popularity'\n",
    "    p = data.loc[:,:lastPredictor].columns.size\n",
    "    n = len(data.index)\n",
    "    learning_set_sizes = {'2p': 2*p, '10p': 10*p}\n",
    "    misclassification_rates = {\n",
    "        'train': {\n",
    "            '2p': [],\n",
    "            '10p': []\n",
    "        },\n",
    "        'test': {\n",
    "            '2p': [],\n",
    "            '10p': []\n",
    "        }\n",
    "    }\n",
    "    optimal_params = {'2p': [], '10p': []}\n",
    "    for iteration in range(iters):\n",
    "        print(iteration)\n",
    "        for size_case in learning_set_sizes:\n",
    "            #print('-'*80)\n",
    "            #print (\"iteration: \", iteration+1, \" of \", iters)\n",
    "            #print(\"case: \", size_case)\n",
    "            size = learning_set_sizes[size_case]\n",
    "            train_set,test_set = train_test_split(data, test_size= 1.0*size/n)\n",
    "            x_train, y_train, x_test, y_test = make_train_test(train_set, test_set, lastPredictor, columnOutput)\n",
    "            clf, y_pred_train, y_pred_test = classifier(x_train, y_train, x_test)\n",
    "            misclassification_rates['train'][size_case].append(1.0 - accuracy_score(y_train, y_pred_train))\n",
    "            misclassification_rates['test'][size_case].append(1.0 - accuracy_score(y_test, y_pred_test))\n",
    "            #print('-'*80)\n",
    "    results[name] = misclassification_rates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:193: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('OnlineNewsPopularity.csv') \n",
    "std_data=prepare(data.iloc[0:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---RANDOM FOREST---\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "time elapsed =  3.6995514589999914 s\n",
      "\n",
      "---LOGISTIC---\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "time elapsed =  4.211847442999996 s\n",
      "\n",
      "---LASSO---\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "time elapsed =  2.809018715999997 s\n",
      "\n",
      "---ELASTIC NET---\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "time elapsed =  2.1248623510000044 s\n",
      "\n",
      "---RIDGE---\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed =  28.11048624 s\n",
      "\n",
      "---RADIAL SVM---\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "time elapsed =  53.71903432300002 s\n",
      "{   'ELASTIC NET': {   'test': {   '10p': [   0.5241379310344827,\n",
      "                                              0.4482758620689655,\n",
      "                                              0.5189655172413793,\n",
      "                                              0.4948275862068966,\n",
      "                                              0.5103448275862069],\n",
      "                                   '2p': [   0.4051724137931034,\n",
      "                                             0.4482758620689655,\n",
      "                                             0.3706896551724138,\n",
      "                                             0.4482758620689655,\n",
      "                                             0.5258620689655172]},\n",
      "                       'train': {   '10p': [   0.44166666666666665,\n",
      "                                               0.25,\n",
      "                                               0.4666666666666667,\n",
      "                                               0.4666666666666667,\n",
      "                                               0.3916666666666667],\n",
      "                                    '2p': [   0.3664383561643836,\n",
      "                                              0.3904109589041096,\n",
      "                                              0.4058219178082192,\n",
      "                                              0.398972602739726,\n",
      "                                              0.3595890410958904]}},\n",
      "    'LASSO': {   'test': {   '10p': [   0.4568965517241379,\n",
      "                                        0.4620689655172414,\n",
      "                                        0.48793103448275865,\n",
      "                                        0.4862068965517241,\n",
      "                                        0.5051724137931035],\n",
      "                             '2p': [   0.4224137931034483,\n",
      "                                       0.5517241379310345,\n",
      "                                       0.43965517241379315,\n",
      "                                       0.39655172413793105,\n",
      "                                       0.4482758620689655]},\n",
      "                 'train': {   '10p': [   0.275,\n",
      "                                         0.42500000000000004,\n",
      "                                         0.5,\n",
      "                                         0.4083333333333333,\n",
      "                                         0.4083333333333333],\n",
      "                              '2p': [   0.386986301369863,\n",
      "                                        0.3955479452054794,\n",
      "                                        0.38869863013698636,\n",
      "                                        0.38869863013698636,\n",
      "                                        0.398972602739726]}},\n",
      "    'LOGISTIC': {   'test': {   '10p': [   0.47413793103448276,\n",
      "                                           0.42931034482758623,\n",
      "                                           0.47931034482758617,\n",
      "                                           0.4913793103448276,\n",
      "                                           0.5],\n",
      "                                '2p': [   0.47413793103448276,\n",
      "                                          0.3448275862068966,\n",
      "                                          0.43965517241379315,\n",
      "                                          0.4224137931034483,\n",
      "                                          0.3879310344827587]},\n",
      "                    'train': {   '10p': [   0.125,\n",
      "                                            0.04166666666666663,\n",
      "                                            0.275,\n",
      "                                            0.20833333333333337,\n",
      "                                            0.125],\n",
      "                                 '2p': [   0.33390410958904104,\n",
      "                                           0.40068493150684936,\n",
      "                                           0.39212328767123283,\n",
      "                                           0.3407534246575342,\n",
      "                                           0.35787671232876717]}},\n",
      "    'RADIAL SVM': {   'test': {   '10p': [   0.49310344827586206,\n",
      "                                             0.5,\n",
      "                                             0.5155172413793103,\n",
      "                                             0.4706896551724138,\n",
      "                                             0.5172413793103448],\n",
      "                                  '2p': [   0.4137931034482759,\n",
      "                                            0.4655172413793104,\n",
      "                                            0.4224137931034483,\n",
      "                                            0.4137931034482759,\n",
      "                                            0.4224137931034483]},\n",
      "                      'train': {   '10p': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
      "                                   '2p': [   0.0,\n",
      "                                             0.003424657534246589,\n",
      "                                             0.0,\n",
      "                                             0.005136986301369828,\n",
      "                                             0.008561643835616417]}},\n",
      "    'RANDOM FOREST': {   'test': {   '10p': [   0.4706896551724138,\n",
      "                                                0.48275862068965514,\n",
      "                                                0.4672413793103448,\n",
      "                                                0.46896551724137936,\n",
      "                                                0.4568965517241379],\n",
      "                                     '2p': [   0.31896551724137934,\n",
      "                                               0.4137931034482759,\n",
      "                                               0.3275862068965517,\n",
      "                                               0.4568965517241379,\n",
      "                                               0.4568965517241379]},\n",
      "                         'train': {   '10p': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
      "                                      '2p': [0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
      "    'RIDGE': {   'test': {   '10p': [   0.49310344827586206,\n",
      "                                        0.5137931034482759,\n",
      "                                        0.4862068965517241,\n",
      "                                        0.5224137931034483,\n",
      "                                        0.4844827586206897],\n",
      "                             '2p': [   0.47413793103448276,\n",
      "                                       0.4224137931034483,\n",
      "                                       0.4224137931034483,\n",
      "                                       0.4137931034482759,\n",
      "                                       0.47413793103448276]},\n",
      "                 'train': {   '10p': [   0.475,\n",
      "                                         0.4916666666666667,\n",
      "                                         0.375,\n",
      "                                         0.44999999999999996,\n",
      "                                         0.2833333333333333],\n",
      "                              '2p': [   0.36472602739726023,\n",
      "                                        0.37328767123287676,\n",
      "                                        0.3664383561643836,\n",
      "                                        0.37328767123287676,\n",
      "                                        0.37671232876712324]}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\n",
    "         'RANDOM FOREST': random_forest,\n",
    "         'LOGISTIC': logistic_plain_cv,\n",
    "         'LASSO': lasso_cv,\n",
    "         'ELASTIC NET': elastic_net_cv,\n",
    "         'RIDGE': ridge_cv,\n",
    "         'RADIAL SVM': svc,\n",
    "   }\n",
    "\n",
    "def run_with_timer(label, data, classifierCallable):\n",
    "    print(\"\\n---\" + label + \"---\")\n",
    "    r = partial(run_model, data, label, classifierCallable)\n",
    "    print(\"time elapsed = \", timeit(r, number=1), \"s\")\n",
    "\n",
    "for l in config:\n",
    "   run_with_timer(l, std_data, config[l])\n",
    "    \n",
    "pp.pprint(results)\n",
    "\n",
    "# restructured_results = {\n",
    "# '2p':{\n",
    "#     'train': {},\n",
    "#     'test':{}\n",
    "# },\n",
    "#     '10p': {\n",
    "#         'train': {},\n",
    "#         'test': {}\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# for k in results:\n",
    "#     restructured_results['2p']['train'][k] = results[k]['train']['2p']\n",
    "#     restructured_results['2p']['test'][k] = results[k]['test']['2p']\n",
    "#     restructured_results['10p']['train'][k] = results[k]['train']['10p']\n",
    "#     restructured_results['10p']['test'][k] = results[k]['test']['10p']\n",
    "    \n",
    "# pp.pprint(restructured_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# err_2p = restructured_results['2p']\n",
    "# err_10p = restructured_results['10p']\n",
    "\n",
    "# def make_plot(errs,label, p):\n",
    "#     #x\n",
    "#     X = list(errs['train'].keys())\n",
    "#     #y\n",
    "#     Y = {k:errs[k].values() for k in errs}\n",
    "#     #col\n",
    "#     COL = list(errs.keys())\n",
    "#     fig, axes = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(9, 6))\n",
    "#     # rectangular box plot\n",
    "#     bplot1 = axes[0].boxplot(list(Y['train']),\n",
    "#                          vert=True,   # vertical box aligmnent\n",
    "#                          patch_artist=True)   # fill with color\n",
    "#     axes[0].set_xlabel(\"Training errors\", fontsize=14)\n",
    "#     axes[0].set_ylabel('Misclassification rate', fontsize=14)\n",
    "\n",
    "#     # notch shape box plot\n",
    "#     bplot2 = axes[1].boxplot(list(Y['test']),\n",
    "#                          vert=True,   # vertical box aligmnent\n",
    "#                          patch_artist=True)   # fill with color\n",
    "#     axes[1].set_xlabel(\"Test errors\", fontsize=14)\n",
    "\n",
    "#     # fill with colors\n",
    "#     colors = ['pink', 'lightblue', 'lightgreen', 'red', 'orange', 'yellow']\n",
    "#     for bplot in (bplot1, bplot2):\n",
    "#         for patch, color in zip(bplot['boxes'], colors):\n",
    "#             patch.set_facecolor(color)\n",
    "\n",
    "#     # adding horizontal grid lines\n",
    "#     for ax in axes:\n",
    "#         ax.yaxis.grid(True)\n",
    "#         ax.set_xticklabels(X, rotation = 90)\n",
    "#     plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "#     fig.suptitle(\"$n_{learn} = \"+ label +\" = \"+str(p)+\"$\", fontsize=20)\n",
    "\n",
    "#     plt.savefig(label+'.png', dpi=1200)\n",
    "#     plt.show()\n",
    "    \n",
    "# make_plot(err_2p, '2p', 118)\n",
    "# make_plot(err_10p, '10p', 580)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
